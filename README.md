# Proximal Policy Optimization with Heuristic on Trajectories Divergence

This repository contains an implementation of a modification of Proximal Policy Optimization (PPO) that enforces a trust region constraint on the trajectories generated by the old and new policies. This enhancement improves convergence and overall performance while preserving the simplicity of the original algorithm through minimal changes.

## Features

* **Trust Region on Trajectories**: Enforces a constraint to keep the KL divergence between old and new policy trajectories within a specified bound.
* **Minimal Modifications**: Builds upon the standard PPO framework with only a few additional lines of code.
* **Easy Experimentation**: Provides a simple interface for running experiments on standard OpenAI Gym environments.

## Prerequisites

* [Docker](https://www.docker.com/) installed on your system.
* [Git](https://git-scm.com/) for cloning the repository.

## Getting Started

Follow these steps to get up and running:

1. **Clone the repository**

   ```bash
   git clone https://github.com/rbouftini/ppoh.git
   cd ppoh
   ```

2. **Build the Docker image**

   ```bash
   docker build -t ppoh .
   ```

3. **Start a Docker container with a Bash session**

   * **PowerShell**

     ```powershell
     docker run -it --mount "type=bind,src=$($pwd),target=/ppoh" ppoh bash
     ```

   * **bash/zsh**

     ```bash
     docker run -it --mount type=bind,src="$(pwd)",target=/ppoh ppoh bash
     ```

4. **Run experiments**

   Inside the container, execute the `run.py` script with your desired configuration. For example:

   ```bash
   python run.py --alg=new --env=LunarLander-v3 --num-eps=100
   ```

   For additional information about arguments, you can run the script with --help flag:
   ```bash
   python run.py --help
   usage: run.py [-h] [--alg {new,ppo}] [--env ENV] [--num-eps NUM_EPS]

   optional arguments:
  -h, --help         show this help message and exit
  --alg {new,ppo}    Testing Algorithm
  --env ENV          Environment id (eg. LunarLander-v3)
  --num-eps NUM_EPS  Number of episodes
  ```
  

## Repository Structure

```
ppoh/
├── .dockerignore
├── .gitignore
├── ContinuousAgent.py # Agent for continuous-action environments
├── DiscreteAgent.py # Agent for discrete-action environments
├── Dockerfile # Docker instructions file
├── README.md # (this file)
├── new.py # New PPO algorithm implementation
├── ppo.py # PPO implementation
├── requirements.txt # Python dependencies
└── run.py # Script for running experiments
```

## License

This project is licensed under the MIT License. See the [LICENSE](LICENSE) file for details.
